{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining Massive Datasets Problem Set 9\n",
    "\n",
    "Ruben Hartenstein, Taha Erkoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "In a clique, every node is connected to every other node which means that all nodes have the same in- and out-degree. Thus each node contributes and receives the same fraction of its PageRank. This symmetric structure allows for the flow of the PageRank to be uniform across all nodes in the clique.\n",
    "\n",
    "### b)\n",
    "\n",
    "The general form of matrix A is as follows:\n",
    "\n",
    "$A = \\beta * M + (1-\\beta) * [\\frac{1}{N}]_{NXN}$\n",
    "\n",
    "When a node is a dead-end (has no outgoing links), its corresponding column in $M$ contains all zeros. To make $M$ a valid stochastic matrix, we replace the entire column of the dead-end nodes with $1/N$, saying there is a uniform probability to any other node. Doing this our matrix $M$ remains column-stochastic (each column sums up to $1$) and random teleport links are followed with a probability $1.0$ from dead-ends.\n",
    "\n",
    "With this approach, the teleportation is already incorperated in our new matrix $M$ and our teleportation matrix $(1-\\beta) * [\\frac{1}{N}]_{NXN}$ no longer needs to adress the dead-end issue. It only serves as a random jump mechanism across all nodes.\n",
    "\n",
    "### c) (in the PDF)\n",
    "\n",
    "\n",
    "### d)\n",
    "\n",
    "With random teleports we give the surfer a probability of $1 - \\beta$ of jumping to a random page outside the spider trap rather than following links within the trap. This prevents the pagerank score from being permanently trapped.\n",
    "\n",
    "For Dead-ends, with random teleports a surfer at a dead-end is assumed to teleport to any other page in the graph with an equal probability of $1/N$. For our formula this means that we replace the dead-end column in $M$ with uniform probabilities $1/N$, restoring the column-stochastic property. This ensures our matrix $M$ remanins valid for the PageRank calculation the algorithm converges to a meaningful result regardless of the graph structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lit, input_file_name, concat_ws, collect_list, size, array_distinct\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"CharacterShingling\").getOrCreate()\n",
    "path = \"/grundgesetz/brd_grundgesetz_63_2019-04-03.txt\"\n",
    "\n",
    "# Load all text files from folder into a DataFrame\n",
    "documents = spark.read.text(path).withColumnRenamed(\"value\", \"text\")\n",
    "\n",
    "# Add column for file name\n",
    "documents = documents.withColumn(\"file_name\", input_file_name())\n",
    "\n",
    "# Group documents by file name and concatenate to single block of text\n",
    "documents_grouped = documents.groupBy(\"file_name\").agg(\n",
    "    concat_ws(\" \", collect_list(\"text\")).alias(\"full_text\")\n",
    ")\n",
    "\n",
    "\n",
    "# Function to generate shingles of size k from a text\n",
    "def generate_shingles(text, k):\n",
    "    shingles = set()\n",
    "\n",
    "    # Handle line breaks, hyphens and remove extra spaces\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"- \", \"\").replace(\"\\r\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    # Generate shingles\n",
    "    for i in range(len(text) - k + 1):\n",
    "        shingle = text[i:i + k]\n",
    "        shingles.add(shingle)\n",
    "\n",
    "    return list(shingles)\n",
    "\n",
    "\n",
    "# Register the function as a UDF\n",
    "shingles_udf = udf(lambda text, k: generate_shingles(text, k), ArrayType(StringType()))\n",
    "\n",
    "# Generate shingles for k = 5 and k = 9\n",
    "results = {}\n",
    "for k in [5, 9]:\n",
    "    # Add column for shingles of size k\n",
    "    shingles_df = documents_grouped.withColumn(f\"shingles_{k}\", shingles_udf(col(\"full_text\"), lit(k)))\n",
    "\n",
    "    # Add column for the number of distinct shingles\n",
    "    shingles_count_df = shingles_df.withColumn(f\"distinct_shingles_{k}\", size(array_distinct(col(f\"shingles_{k}\"))))\n",
    "\n",
    "    # Add results to the dictionary\n",
    "    results[k] = shingles_count_df.select(\"file_name\", f\"distinct_shingles_{k}\")\n",
    "\n",
    "    # Filter results for the Grundgesetz\n",
    "    grundgesetz_results = results[k].filter(col(\"file_name\").contains(\"grundgesetz\"))\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\nResults for k={k}:\")\n",
    "    results[k].show(truncate=False)\n",
    "\n",
    "    print(f\"\\nGrundgesetz results for k={k}:\")\n",
    "    grundgesetz_results.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "Hash functions\n",
    "\n",
    "$h_1(x) = (2x + 1) \\mod{6} $ <br>\n",
    "$h_2(x) = (3x + 2) \\mod{6} $ <br>\n",
    "$h_3(x) = (5x + 2) \\mod{6} $ <br>\n",
    "\n",
    "Now we compute the hash values for $x \\in \\{0,1,2,3,4,5\\}$\n",
    "\n",
    "For $h_1(x) = (2x + 1) \\mod{6} $:\n",
    "\n",
    "$h_1(0) = 1$ <br>\n",
    "$h_1(1) = 3$ <br>\n",
    "$h_1(2) = 5$ <br>\n",
    "$h_1(3) = 1$ <br>\n",
    "$h_1(4) = 3$ <br>\n",
    "$h_1(5) = 5$ <br>\n",
    "\n",
    "For $h_2(x) = (3x + 2) \\mod{6} $:\n",
    "\n",
    "$h_2(0) = 2$ <br>\n",
    "$h_2(1) = 5$ <br>\n",
    "$h_2(2) = 2$ <br>\n",
    "$h_2(3) = 5$ <br>\n",
    "$h_2(4) = 2$ <br>\n",
    "$h_2(5) = 5$ <br>\n",
    "\n",
    "For $h_3(x) = (5x + 2) \\mod{6}$:\n",
    "\n",
    "$h_3(0) = 2$ <br>\n",
    "$h_3(1) = 1$ <br>\n",
    "$h_3(2) = 0$ <br>\n",
    "$h_3(3) = 5$ <br>\n",
    "$h_3(4) = 4$ <br>\n",
    "$h_3(5) = 3$ <br>\n",
    "\n",
    "### MinHash Signature for each set:\n",
    "\n",
    "$S_1 \\{2,5\\}$ (non-zero entries in $S_1$):\n",
    "\n",
    "$h_1(2) = 5, h_1(5) = 5$, $Min = 5$<br>\n",
    "$h_2(2) = 2, h_2(5) = 5$, $Min = 2$<br>\n",
    "$h_3(2) = 0, h_3(5) = 3$, $Min = 0$<br>\n",
    "\n",
    "The same for sets $S_2,S_3,S_4$, the signature table looks like:\n",
    "\n",
    "| Set  | $h_1 Min$ | $h_2 Min$ | $h_3 Min$|\n",
    "|------|-----------|-----------|----------|\n",
    "| $S_1$| 5         | 2         | 0        |\n",
    "| $S_2$| 1         | 2         | 1        |\n",
    "| $S_3$| 1         | 2         | 4        |\n",
    "| $S_4$| 1         | 2         | 0        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### b)\n",
    "$h_3(x)$ is a true permutation because all hash values $\\{0,1,2,3,4,5\\}$ are distinct.\n",
    "\n",
    "Collisions:\n",
    "\n",
    "$h_1(x)$: <br>\n",
    "$h_1(0) = h_1(3) = 1$ <br>\n",
    "$h_1(1) = h_1(4) = 3$ <br>\n",
    "$h_1(2) = h_1(5) = 5$ <br>\n",
    "\n",
    "$h_2(x)$: <br>\n",
    "$h_2(0) = h_2(2) = h_2(4) = 2$ <br>\n",
    "$h_2(1) = h_2(3) = h_2(5)= 3$ <br>\n",
    "\n",
    "\n",
    "### c)\n",
    "| Pair        | MinHash Similarity | Jaccard Similarity |\n",
    "|-------------|--------------------|--------------------|\n",
    "| $S_1$,$S_2$ | 0.33               | 0                  |\n",
    "| $S_1$,$S_3$ | 0.33               | 0                  |\n",
    "| $S_1$,$S_4$ | 0.67               | 0.33               |\n",
    "| $S_2$,$S_3$ | 0.33               | 0                  |\n",
    "| $S_2$,$S_4$ | 0.67               | 0.33               |\n",
    "| $S_3$,$S_4$ | 0.33               | 0.33               |\n",
    "\n",
    "Due to the small number of hash functions we cannot see that the MinHash similarity would actually converge to the true Jaccard similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1234, 2345, 3456, 4567]\n"
     ]
    }
   ],
   "source": [
    "def compute_k_shingles(digits, k):\n",
    "    # Set to store unique positions\n",
    "    positions = set()\n",
    "\n",
    "    # Iterate over the digits\n",
    "    for i in range(len(digits) - k + 1):\n",
    "        # Get k-shingle at current position\n",
    "        shingle = digits[i:i+k]\n",
    "        # Convert to integer and add to set\n",
    "        positions.add(int(shingle))\n",
    "\n",
    "    # Return ordered list of unique positions\n",
    "    return sorted(positions)\n",
    "\n",
    "# Test function with example\n",
    "test_example = \"1234567\"\n",
    "k = 4\n",
    "shingles = compute_k_shingles(test_example, k)\n",
    "print(shingles)  # Expected: [1234, 2345, 3456, 4567]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpmath import mp\n",
    "\n",
    "# Set precision to 10000 digits\n",
    "mp.dps = 10000\n",
    "\n",
    "# Get pi as string after decimal point\n",
    "pi_digits = str(mp.pi)[2:]\n",
    "\n",
    "# Apply shingles function with k = 12\n",
    "k = 12\n",
    "shingles_positions = compute_k_shingles(pi_digits, k)\n",
    "\n",
    "# Save output to text file\n",
    "with open(\"k_shingles_pi.txt\", \"w\") as f:\n",
    "    for pos in shingles_positions:\n",
    "        f.write(f\"{pos}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinHash Signature: [11610003501, 63680740533, 107687383220, 41635782020, 203614208147]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def minhash_signature(positions, hash_functions):\n",
    "    # Initialize signature\n",
    "    signature = []\n",
    "\n",
    "    # Iterate over hash functions\n",
    "    for a, b, p in hash_functions:\n",
    "        min_hash = float(\"inf\")\n",
    "        # Compute hash value for each position and track the minimum\n",
    "        for pos in positions:\n",
    "            hash_value = ((a * pos + b) % p) % (10**15)\n",
    "            min_hash = min(min_hash, hash_value)\n",
    "        signature.append(min_hash)\n",
    "    return signature\n",
    "\n",
    "def generate_hash_functions():\n",
    "    hash_functions = []\n",
    "    # First hash function\n",
    "    hash_functions.append((37, 126, 10**15 + 223))\n",
    "    \n",
    "    # Generate 4 additional hash functions\n",
    "    for i in [37, 91, 159, 187]:\n",
    "        a = random.randint(0, 10**12)\n",
    "        b = random.randint(0, 10**12)\n",
    "        p = 10**15 + i\n",
    "        hash_functions.append((a, b, p))\n",
    "    \n",
    "    return hash_functions\n",
    "\n",
    "\n",
    "# Generate hash functions\n",
    "hash_functions = generate_hash_functions()\n",
    "\n",
    "# Compute MinHash signature\n",
    "signature = minhash_signature(shingles_positions, hash_functions)\n",
    "\n",
    "# Output the MinHash signature\n",
    "print(\"MinHash Signature:\", signature)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
