{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "- The probability that a single machine does not fail during the time period $T$ is $1 - p$.\n",
    "- For $n$ machines, assuming failures are independent, the probabilty that none of the $n$ machines fail is: $(1 - p)^n$.\n",
    "- The probability of at least one machine failing is the complement of this event: <br> $P(at\\ least\\ one\\ failure) = 1 - P(no\\ failures) = 1 - (1 - p)^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "The probability $p_k$ of exactly $k$ machines failing can be modeled using the binoial distribution, since each machine independently either fails or does not fail.<br><br>\n",
    "$p_k = \\binom{n}{k} p^k (1 - p)^{n-k}$ <br><br>\n",
    "Where:<br>\n",
    "- $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$: is the binomial coefficient, representing the number of ways to choose $k$ failing machines out of $n$.\n",
    "- $p^k$: Probability of $k$ machines failing.\n",
    "- $(1 - p)^{n - k}$: Probability of the remaining $n - k$ machines not failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "The binomial distribution guarantees that the sum of probabilities for all possible outcomes (from $0$ to $n$ failures) equals $1$.<br> <br>\n",
    "$p_0 + p_1 + \\ldots + p_n = 1$ <br><br>\n",
    "Here: <br>\n",
    "- $p_0 = (1 - p)^n$ : probabilities of no failures.\n",
    "- $p_1 + p_2 + \\ldots + p_n$: probability of at least one failure.\n",
    "\n",
    "Therefore:<br><br>\n",
    "$p_1 + p_2 + \\ldots + p_n = 1 - p_0 = 1 - (1 - p)^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHA-256 (Secure Hash Algorithm 256-bit)\n",
    "- Converts input data into a fixed-length 256-bit hash.\n",
    "- Commonly used in cryptographic applications like digital signatures and password storage.\n",
    "### MD5 (Message Digest Algorithm 5)\n",
    "- Produces a 128-bit hash value.\n",
    "- Historically used for password hashing but is now considered insecure against brute-force and collision attacks.\n",
    "\n",
    "### Connection of Hash Functions to Password Security\n",
    "Hash functions are vital for securely storing passwords because:\n",
    "1. They transform as password into a fixed-size hash, making the original password irrecoverable.\n",
    "2. Good hash functions are designed to be:\n",
    "    - __Deterministic__: Same input always produces the same output:\n",
    "    - __Non-reversible__: It's computationally infeasible to derive the original input from the hash.\n",
    "    - __Collision-resistant__: Different inputs should produce unique hashes.\n",
    "\n",
    "However, if basic hash functions (like unsalted MD5 or SHA-1) are used without additional security measures, they bacome vulnerable to rainbow table attacks.\n",
    "\n",
    "### Rainbow Table\n",
    "A rainbow table is a precomputed table of hashes for a large set of possible passwords. It is used to reverse-engineer hashed passwords by looking up their hash values:\n",
    "- Trade-off: Reduces computational cost of cracking hashes by using storage space.\n",
    "- Threat: Enables attackers to match hash values quickly to their plaintext equivalents, especially for commonly used passwords.\n",
    "\n",
    "### Salt\n",
    "Salt is a random string of data added to a password before hashing it. Its purpose is to:\n",
    "1. Ensure that even if two users have the same password, their hashes will be unique.\n",
    "2. Defeat precomputed rainbow tables, as the salt must also be known to match the hash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Data Structure\n",
    "1.  Buckets\n",
    "    -   The HashMap uses an array (`Node<K,V>[] table`) to store key-value pairs. Each element in the array represents a bucket.\n",
    "2.  Node Class\n",
    "    -   Each bucket contains a `Node` object that stores:\n",
    "        -   `key`: The key of the mapping.\n",
    "        -   `value`: The associated value.\n",
    "        -   `hash`: The hash code of the key.\n",
    "        -   `next`: A reference to the next node in the bucket (for collision handling via chaining).\n",
    "3.  Tree Nodes\n",
    "    -   If the number of entries in a bucket exceeds the `TREEIFY_THRESHOLD` (8 by default) the bucket switches to a tree structure (red-black tree). This improves the efficiency of operations from $O(n)$ to $O(log(n))$.\n",
    "### Adding a `<Key, Value>` Pair\n",
    "1. Hash Computation\n",
    "    -   A key's hash code is computed using `hash(key)` which applies a transformation to reduce collisions.\n",
    "2. Bucket Index\n",
    "    - The bucket index is calculated using `index = (hash & (table.length - 1))`.\n",
    "3.  Collision Handling:\n",
    "    -   If the bucket at the computed index is empty, a new node is placed directly.\n",
    "    -   If the bucket already has entries:\n",
    "        - The chain of nodes is traversed using `Node.next` to find an existing key or reach the end.\n",
    "        -   If the key exists (determined using `equals()`), its value is updated.\n",
    "        -   Otherwise, a new node is appended at the end of the chain.\n",
    "    -   If the chain lenght exceeds `TREEIFY_THRESHOLD`, the chain is converted into a red-black tree.\n",
    "4. Rehashing\n",
    "    -   If the number of entries exceeds the threshold (capacity * load factor), the table is resized (doubled), and the entries are rehashed to redistribute them across the new buckets.\n",
    "### Retrieving an Entry\n",
    "1. Hash Computation and Index Lookup:\n",
    "    -   The key's hash is computed, and the bucket index is determined.\n",
    "2. Bucket Traversal:\n",
    "    -   The bucket at the computed index is traversed:\n",
    "        - If the bucket is a linked list, the nodes are scanned sequentially, comparing the key using `equals()`\n",
    "        - If the bucket is a tree, a tree search is performed based on the key's hash and order (if keys are comparable).\n",
    "3. Return Value:\n",
    "    - If a matching key is found, its value is returned.\n",
    "    - If no match is found `null` is returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MurmurHash3:\n",
    "    -   Description: A non-cryptographic hash function that provides high-quality, uniformly distributed hash values.\n",
    "    - Justification: MurmurHash3 is widely used for its speed and high-quality hash distribution. It provides good mixing properties and is robust against clustering, making it ideal for Bloom filters.\n",
    "2. FNV-1a (Fowler-Noll-Vo):\n",
    "    -   Description: A lightweight hash function that sues a prime multiplier for dispersion and processes input byte-by-byte.\n",
    "    - Justification: FNV-1a is simple, fast and produces distinct hash values due to its unique multiplier. Its design complements MurmurHash3 in terms of computation and output.\n",
    "3. CityHash:\n",
    "    -   Description: A hash function designed by Google for fast processing of strings, optimized for low-latency applications.\n",
    "    - Justification: CityHash offers a good tradeoff between speed and uniformity of hash values. Its implementation uses techniques like hashing chunks of data efficiently, which differ significantly from MurmurHash3 and FNV-1a.\n",
    "\n",
    "Each hash function employs distinct approaches for combining and distributing input data (bit-mixing, prime-based linear methods and block hashing). Their differing internal designs minimize the likelihood of correlated outputs for similar inputs and therefore reducing false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "The probability formula for a random element hashing to a specific bit in the Bloom filter is: $P(hit) = \\frac{1}{n}$\n",
    "\n",
    "Where $n = 5$ (number of bits in the array). Thus, the probability that a random element gets hashed to a given bit is: $P(hit) = \\frac{1}{5} = 20\\%$.\n",
    "\n",
    "This probability arises because each bit in the bit array is equally likely to be chosen by the hash function of a random element, assuming the hash function distributes values uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "$h_1(x) = x\\ mod\\ 5$<br>\n",
    "$h_2(x) = (2x + 3)\\ mod\\ 5$\n",
    "\n",
    "\n",
    "For $x = 4$:\n",
    "\n",
    "\n",
    "$h_1(4) = 4\\ mod\\ 5 = 4$<br>\n",
    "$h_2(4) = 11\\ mod\\ 5 = 1$<br>\n",
    "\n",
    "|  0   |  1   |  2   |  3   |  4   |\n",
    "|-----|-----|-----|-----|-----|\n",
    "| 0 | 1 | 0 | 0 | 1 |\n",
    "\n",
    "\n",
    "For $x = 1$:\n",
    "\n",
    "\n",
    "$h_1(4) = 1\\ mod\\ 5 = 1$<br>\n",
    "$h_2(4) = 5\\ mod\\ 5 = 0$<br>\n",
    "\n",
    "|  0   |  1   |  2   |  3   |  4   |\n",
    "|-----|-----|-----|-----|-----|\n",
    "| 1 | 1 | 0 | 0 | 1 |\n",
    "\n",
    "Every bit is equally likely to be hit by the two hash functions if the input values are uniformly distributed.\n",
    "- $h_1(x)$ simply maps $x$ to its remainder when divided by 5. Since it cylcles through all possible values as $x$ increases, it uniformly distributes across the 5 bits if $x$ itself is uniformly distributed.\n",
    "- $h_2(x)$ also distributes the values uniformly since the GCD of 2 and 5 is 1 (2 is relatively prime to 5 since they're both prime numbers). This property ensures that the mapping $2x\\ mod\\ 5$ generates a complete cycle over all residues before repeating. Adding 3 doesn't change the uniformity but merely shifts the sequence cyclically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "$P_{false\\ positive} = (1 - e^{-\\frac{k*n}{m}})^k$\n",
    "\n",
    "Where:\n",
    "- $k = 2$ (number of hash functions)\n",
    "- $n = 2$ (number of elements inserted)\n",
    "- $m = 5$ (size of the bit array)\n",
    "\n",
    "The fraction of 1s in the bit array is determined by $1 - e^{-\\frac{k*n}{m}} = 0,551$. Thus, approximaltey $55,1\\%$ of the bits are expected to be set, resulting in a $P_{false\\ positive} = (0,551)^2 = 0,304$.\n",
    "\n",
    "The false positive probability is approximatley $30,4\\%$. This means that for any random number checked against the Bloom filter, there is about a $30,4\\%$ chance it will falsely appear to be in the set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
